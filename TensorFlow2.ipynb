{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentals of TensorFlow 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import constant, Variable \n",
    "from tensorflow import multiply, ones_like, matmul\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core TensorFlow Opertions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.] \n",
      "\n",
      "[1. 1.] \n",
      "\n",
      "[[1. 1.]\n",
      " [1. 1.]] \n",
      "\n",
      "[[[1. 1.]\n",
      "  [1. 1.]]\n",
      "\n",
      " [[1. 1.]\n",
      "  [1. 1.]]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 0D Tensor\n",
    "d0 = tf.ones((1,))\n",
    "print(d0.numpy(), \"\\n\")\n",
    "\n",
    "# 1D Tensor\n",
    "d1 = tf.ones((2,))\n",
    "print(d1.numpy(), \"\\n\")\n",
    "\n",
    "# 2D Tensor\n",
    "d2 = tf.ones((2, 2))\n",
    "print(d2.numpy(), \"\\n\")\n",
    "\n",
    "# 3D Tensor\n",
    "d3 = tf.ones((2, 2, 2))\n",
    "print(d3.numpy(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(d0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(d0.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants and Variables\n",
    "\n",
    "Constants are the simplest category of tensor in TensorFlow. They are not trainable, but can have dimensions. Tensorflow version 2.0 allows us to use data as either a **numpy array** or a **tensorflow constant** object. Using a constant will ensure that any operations performed with that object are done in tensorflow.\n",
    "\n",
    "Unlike a constant, a **variable**'s value can be modified. This will be quite useful when we want to train a model by updating its parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272.0</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>14948.0</td>\n",
       "      <td>15549.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314.0</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>29547.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940.0</td>\n",
       "      <td>19146.0</td>\n",
       "      <td>19131.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>36681.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0   1    20000.0    2          2         1   24      2      2     -1     -1   \n",
       "1   2   120000.0    2          2         2   26     -1      2      0      0   \n",
       "2   3    90000.0    2          2         2   34      0      0      0      0   \n",
       "3   4    50000.0    2          2         1   37      0      0      0      0   \n",
       "4   5    50000.0    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0  ...        0.0        0.0        0.0       0.0     689.0       0.0   \n",
       "1  ...     3272.0     3455.0     3261.0       0.0    1000.0    1000.0   \n",
       "2  ...    14331.0    14948.0    15549.0    1518.0    1500.0    1000.0   \n",
       "3  ...    28314.0    28959.0    29547.0    2000.0    2019.0    1200.0   \n",
       "4  ...    20940.0    19146.0    19131.0    2000.0   36681.0   10000.0   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
       "0       0.0       0.0       0.0                           1  \n",
       "1    1000.0       0.0    2000.0                           1  \n",
       "2    1000.0    1000.0    5000.0                           0  \n",
       "3    1100.0    1069.0    1000.0                           0  \n",
       "4    9000.0     689.0     679.0                           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "df = pd.read_csv('data/tf/credit.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data as numpy array\n",
    "credit_numpy = np.genfromtxt('data/tf/credit.csv',delimiter=',', skip_header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.000e+00,  2.000e+04,  2.000e+00,  2.000e+00,  1.000e+00,\n",
       "         2.400e+01,  2.000e+00,  2.000e+00, -1.000e+00, -1.000e+00,\n",
       "        -2.000e+00, -2.000e+00,  3.913e+03,  3.102e+03,  6.890e+02,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  6.890e+02,\n",
       "         0.000e+00,  0.000e+00,  0.000e+00,  0.000e+00,  1.000e+00],\n",
       "       [ 2.000e+00,  1.200e+05,  2.000e+00,  2.000e+00,  2.000e+00,\n",
       "         2.600e+01, -1.000e+00,  2.000e+00,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00,  2.000e+00,  2.682e+03,  1.725e+03,  2.682e+03,\n",
       "         3.272e+03,  3.455e+03,  3.261e+03,  0.000e+00,  1.000e+03,\n",
       "         1.000e+03,  1.000e+03,  0.000e+00,  2.000e+03,  1.000e+00]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_numpy[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The class is: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "The datatype is: <dtype: 'float64'>\n",
      "The shape is: (30000, 25)\n"
     ]
    }
   ],
   "source": [
    "# Convert the credit_numpy array into a tensorflow constant\n",
    "credit_constant = constant(credit_numpy)\n",
    "\n",
    "# Print constant class\n",
    "print('The class is:', type(credit_constant))\n",
    "\n",
    "# Print constant datatype\n",
    "print('The datatype is:', credit_constant.dtype)\n",
    "\n",
    "# Print constant shape\n",
    "print('The shape is:', credit_constant.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(4,) dtype=int32, numpy=array([1, 2, 3, 4], dtype=int32)>\n",
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "# Define the 1-dimensional variable A1\n",
    "A1 = Variable([1, 2, 3, 4])\n",
    "\n",
    "# Print the variable A1\n",
    "print(A1)\n",
    "\n",
    "# Convert A1 to a numpy array and assign it to B1\n",
    "B1 = A1.numpy()\n",
    "\n",
    "# Print B1\n",
    "print(B1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Element-Wise Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1: [1 2 3 4]\n",
      "C23: [[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "# Define tensors A1 and A23 as constants\n",
    "A1 = constant([1, 2, 3, 4])\n",
    "A23 = constant([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Define B1 and B23 to have the correct shape\n",
    "B1 = ones_like(A1)\n",
    "B23 = ones_like(A23)\n",
    "\n",
    "# Perform element-wise multiplication\n",
    "C1 = multiply(A1, B1)\n",
    "C23 = multiply(A23, B23)\n",
    "\n",
    "# Print the tensors C1 and C23\n",
    "print('C1: {}'.format(C1.numpy()))\n",
    "print('C23: {}'.format(C23.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making predictions with matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1687]\n",
      " [-3218]\n",
      " [-1933]\n",
      " [57850]]\n"
     ]
    }
   ],
   "source": [
    "# Define features, params, and bill as constants\n",
    "features = constant([[2, 24], [2, 26], [2, 57], [1, 37]])\n",
    "params = constant([[1000], [150]])\n",
    "bill = constant([[3913], [2682], [8617], [64400]])\n",
    "\n",
    "# Compute billpred using features and params\n",
    "billpred = matmul(features, params)\n",
    "\n",
    "# Compute and print the error\n",
    "error = bill - billpred\n",
    "print(error.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=40, shape=(2, 3, 4), dtype=float32, numpy=\n",
       "array([[[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.ones([2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Operaions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100  65]\n",
      " [238  94]]\n",
      "[[100]\n",
      " [ 65]\n",
      " [238]\n",
      " [ 94]]\n"
     ]
    }
   ],
   "source": [
    "# Generate grayscale image\n",
    "gray = tf.random.uniform([2, 2], maxval=255, dtype='int32')\n",
    "print(gray.numpy())\n",
    "\n",
    "# Reshape grayscale image\n",
    "gray = tf.reshape(gray, [2*2, 1])\n",
    "print(gray.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[107  77  92]\n",
      "  [ 22  69  41]]\n",
      "\n",
      " [[115  15  70]\n",
      "  [ 45 152  28]]]\n",
      "[[107  77  92]\n",
      " [ 22  69  41]\n",
      " [115  15  70]\n",
      " [ 45 152  28]]\n"
     ]
    }
   ],
   "source": [
    "# Generate color image\n",
    "color = tf.random.uniform([2, 2, 3], maxval=255, dtype='int32')\n",
    "print(color.numpy())\n",
    "\n",
    "# Reshape color image\n",
    "color = tf.reshape(color, [2*2, 3])\n",
    "print(color.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradients\n",
    "\n",
    "We can compute the slope with `GradientTape` operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create x and y\n",
    "x = np.linspace(-2, 2)\n",
    "y = x**2\n",
    "\n",
    "# Plot the function y\n",
    "plt.plot(x, y)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.0\n",
      "2.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "def compute_gradient(x0):\n",
    "    # Define x as a variable with an initial value of x0\n",
    "    x = Variable(x0)\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(x)\n",
    "        # Define y using the multiply operation\n",
    "        y = tf.multiply(x, x)\n",
    "    # Return the gradient of y with respect to x\n",
    "    return tape.gradient(y, x).numpy()\n",
    "\n",
    "# Compute and print gradients at x = -1, 1, and 0\n",
    "print(compute_gradient(-1.0))\n",
    "print(compute_gradient(1.0))\n",
    "print(compute_gradient(0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "model = np.array([1., 0., -1.])\n",
    "letter = np.matrix([[1., 0., 1.],[1., 1., 0.],[1., 0., 1.]])\n",
    "\n",
    "# Reshape model from a 1x3 to a 3x1 tensor\n",
    "model = tf.reshape(model, (3, 1))\n",
    "\n",
    "# Multiply letter by model\n",
    "output = tf.matmul(letter, model)\n",
    "\n",
    "# Sum over output and print prediction using the numpy method\n",
    "prediction = tf.reduce_sum(output, )\n",
    "print(prediction.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset as a dataframe\n",
    "housing = pd.read_csv('data/tf/house.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      5650     1.0           0     0  ...      7        1180              0   \n",
       "1      7242     2.0           0     0  ...      7        2170            400   \n",
       "2     10000     1.0           0     0  ...      6         770              0   \n",
       "3      5000     1.0           0     0  ...      7        1050            910   \n",
       "4      8080     1.0           0     0  ...      8        1680              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257           1340   \n",
       "1      1951          1991    98125  47.7210 -122.319           1690   \n",
       "2      1933             0    98028  47.7379 -122.233           2720   \n",
       "3      1965             0    98136  47.5208 -122.393           1360   \n",
       "4      1987             0    98074  47.6168 -122.045           1800   \n",
       "\n",
       "   sqft_lot15  \n",
       "0        5650  \n",
       "1        7639  \n",
       "2        8062  \n",
       "3        5000  \n",
       "4        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[221900. 538000. 180000. ... 402101. 400000. 325000.]\n",
      "tf.Tensor([False False False ... False False False], shape=(21613,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "# Use a numpy array to define price as a 32-bit float\n",
    "price = np.array(housing['price'], np.float32)\n",
    "\n",
    "# Define waterfront as a Boolean using cast\n",
    "waterfront = tf.cast(housing['waterfront'], tf.bool)\n",
    "\n",
    "# Print price and waterfront\n",
    "print(price)\n",
    "print(waterfront)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([221900., 538000., 180000., ..., 402101., 400000., 325000.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-191952d1aad2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compute the mean absolute error (mae)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Print the mean absolute error (mae)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "# Compute the mean absolute error (mae)\n",
    "loss = keras.losses.mse(price, predictions)\n",
    "\n",
    "# Print the mean absolute error (mae)\n",
    "print(loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize a variable named scalar\n",
    "scalar = Variable(1.0, tf.float32)\n",
    "\n",
    "features = np.array([1., 2., 3., 4., 5.])\n",
    "targets = np.array([2., 4., 6., 8., 10.])\n",
    "\n",
    "# Define the model\n",
    "def model(scalar, features = features):\n",
    "    return scalar * features\n",
    "\n",
    "# Define a loss function\n",
    "def loss_function(scalar, features = features, targets = targets):\n",
    "    # Compute the predicted values\n",
    "    predictions = model(scalar, features)\n",
    "    \n",
    "    # Return the mean absolute error loss\n",
    "    return keras.losses.mae(targets, predictions)\n",
    "\n",
    "# Evaluate the loss function and print the loss\n",
    "print(loss_function(scalar).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a linear regression model\n",
    "def linear_regression(intercept, slope, features = size_log):\n",
    "    return intercept + slope * features\n",
    "\n",
    "# Set loss_function() to take the variables as arguments\n",
    "def loss_function(intercept, slope, features = size_log, targets = price_log):\n",
    "    # Set the predicted values\n",
    "    predictions = linear_regression(intercept, slope, features)\n",
    "    \n",
    "    # Return the mean squared error loss\n",
    "    return keras.losses.mse(targets, predictions)\n",
    "\n",
    "# Compute the loss for different slope and intercept values\n",
    "print(loss_function(0.1, 0.1).numpy())\n",
    "print(loss_function(0.1, 0.5).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.547175\n",
      "2.793745\n",
      "2.6988533\n",
      "2.562189\n",
      "2.4747696\n",
      "2.4690053\n",
      "2.4035277\n",
      "2.4218972\n",
      "2.4632747\n",
      "2.4056377\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plot_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-406dc4fd5b65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Plot data and regression line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintercept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_results' is not defined"
     ]
    }
   ],
   "source": [
    "intercept = tf.Variable(5., tf.float32)\n",
    "slope = tf.Variable(0.001, tf.float32)\n",
    "\n",
    "# Initialize an adam optimizer\n",
    "opt = keras.optimizers.Adam(0.5)\n",
    "\n",
    "for j in range(100):\n",
    "    # Apply minimize, pass the loss function, and supply the variables\n",
    "    opt.minimize(lambda: loss_function(intercept, slope), var_list=[intercept, slope])\n",
    "\n",
    "    # Print every 10th value of the loss\n",
    "    if j % 10 == 0:\n",
    "        print(loss_function(intercept, slope).numpy())\n",
    "\n",
    "# Plot data and regression line\n",
    "plot_results(intercept, slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the linear regression model\n",
    "def linear_regression(params, feature1 = size_log, feature2 = bedrooms):\n",
    "\treturn params[0] + feature1*params[1] + feature2*params[2]\n",
    "\n",
    "# Define the loss function\n",
    "def loss_function(params, targets = price_log, feature1 = size_log, feature2 = bedrooms):\n",
    "\t# Set the predicted values\n",
    "\tpredictions = linear_regression(params, feature1, feature2)\n",
    "  \n",
    "\t# Use the mean absolute error loss\n",
    "\treturn keras.losses.mae(targets, predictions)\n",
    "\n",
    "# Define the optimize operation\n",
    "opt = keras.optimizers.Adam()\n",
    "\n",
    "# Perform minimization and print trainable variables\n",
    "for j in range(10):\n",
    "\topt.minimize(lambda: loss_function(params), var_list=[params])\n",
    "\tprint_results(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>148</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>150</td>\n",
       "      <td>151</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>55</td>\n",
       "      <td>63</td>\n",
       "      <td>37</td>\n",
       "      <td>61</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>38</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>142</td>\n",
       "      <td>144</td>\n",
       "      <td>145</td>\n",
       "      <td>147</td>\n",
       "      <td>149</td>\n",
       "      <td>150</td>\n",
       "      <td>151</td>\n",
       "      <td>152</td>\n",
       "      <td>...</td>\n",
       "      <td>173</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>182</td>\n",
       "      <td>182</td>\n",
       "      <td>183</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>160</td>\n",
       "      <td>162</td>\n",
       "      <td>164</td>\n",
       "      <td>166</td>\n",
       "      <td>169</td>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "      <td>...</td>\n",
       "      <td>181</td>\n",
       "      <td>197</td>\n",
       "      <td>195</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>191</td>\n",
       "      <td>192</td>\n",
       "      <td>198</td>\n",
       "      <td>193</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>26</td>\n",
       "      <td>65</td>\n",
       "      <td>86</td>\n",
       "      <td>97</td>\n",
       "      <td>106</td>\n",
       "      <td>117</td>\n",
       "      <td>123</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>175</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>182</td>\n",
       "      <td>183</td>\n",
       "      <td>183</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>185</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>160</td>\n",
       "      <td>164</td>\n",
       "      <td>168</td>\n",
       "      <td>172</td>\n",
       "      <td>175</td>\n",
       "      <td>178</td>\n",
       "      <td>180</td>\n",
       "      <td>182</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>107</td>\n",
       "      <td>106</td>\n",
       "      <td>110</td>\n",
       "      <td>111</td>\n",
       "      <td>108</td>\n",
       "      <td>108</td>\n",
       "      <td>102</td>\n",
       "      <td>84</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  775  776  777  778  \\\n",
       "0    1  142  143  146  148  149  149  149  150  151  ...    0   15   55   63   \n",
       "1    0  141  142  144  145  147  149  150  151  152  ...  173  179  179  180   \n",
       "2    1  156  157  160  162  164  166  169  171  171  ...  181  197  195  193   \n",
       "3    3   63   26   65   86   97  106  117  123  128  ...  175  179  180  182   \n",
       "4    1  156  160  164  168  172  175  178  180  182  ...  108  107  106  110   \n",
       "\n",
       "   779  780  781  782  783  784  \n",
       "0   37   61   77   65   38   23  \n",
       "1  181  181  182  182  183  183  \n",
       "2  193  191  192  198  193  182  \n",
       "3  183  183  184  185  185  185  \n",
       "4  111  108  108  102   84   70  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/tf/slmnist.csv', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 785)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.iloc[:,0].values\n",
    "X = df.iloc[:, 1:].values/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                12560     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 36        \n",
      "=================================================================\n",
      "Total params: 12,732\n",
      "Trainable params: 12,732\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# Define a Keras sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Define the first dense layer\n",
    "model.add(keras.layers.Dense(16, activation='relu', input_shape=(784,)))\n",
    "\n",
    "# Define the second dense layer\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "\n",
    "\n",
    "# Define the output layer\n",
    "model.add(keras.layers.Dense(4, 'softmax'))\n",
    "\n",
    "# Print the model architecture\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 16)                12560     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 12,628\n",
      "Trainable params: 12,628\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define a Keras sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Define the first dense layer\n",
    "model.add(keras.layers.Dense(16, activation='sigmoid', input_shape=[784,]))\n",
    "\n",
    "# Apply dropout to the first layer's output\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "# Define the output layer\n",
    "model.add(keras.layers.Dense(4, 'softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile('adam', loss='categorical_crossentropy')\n",
    "\n",
    "# Print a model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, the sequential API will not be sufficiently flexible to accommodate our desired model architecture and we will need to use the functional API instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm1_inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-6327ee198880>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# For model 1, pass the input layer to layer 1 and layer 1 to layer 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mm1_layer1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm1_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mm1_layer2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm1_layer1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# For model 2, pass the input layer to layer 1 and layer 1 to layer 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'm1_inputs' is not defined"
     ]
    }
   ],
   "source": [
    "# For model 1, pass the input layer to layer 1 and layer 1 to layer 2\n",
    "m1_layer1 = keras.layers.Dense(12, activation='sigmoid')(m1_inputs)\n",
    "m1_layer2 = keras.layers.Dense(4, activation='softmax')(m1_layer1)\n",
    "\n",
    "# For model 2, pass the input layer to layer 1 and layer 1 to layer 2\n",
    "m2_layer1 = keras.layers.Dense(12, activation='relu')(m2_inputs)\n",
    "m2_layer2 = keras.layers.Dense(4, activation='softmax')(m2_layer1)\n",
    "\n",
    "# Merge model outputs and define a functional model\n",
    "merged = keras.layers.add([m1_layer2, m2_layer2])\n",
    "model = keras.Model(inputs=[m1_inputs, m2_inputs], outputs=merged)\n",
    "\n",
    "# Print a model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are passing a target array of shape (2000, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:\n```\nfrom keras.utils import to_categorical\ny_binary = to_categorical(y_int)\n```\n\nAlternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-48361d5ad22f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Complete the fitting operation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    548\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[1;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2536\u001b[0m           \u001b[0;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2537\u001b[0m           training_utils.check_loss_and_target_compatibility(\n\u001b[0;32m-> 2538\u001b[0;31m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[1;32m   2539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2540\u001b[0m       \u001b[0;31m# If sample weight mode has not been set and weights are None for all the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[0;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[1;32m    715\u001b[0m         raise ValueError('You are passing a target array of shape ' +\n\u001b[1;32m    716\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m                          \u001b[0;34m' while using as loss `categorical_crossentropy`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m                          \u001b[0;34m'`categorical_crossentropy` expects '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m                          \u001b[0;34m'targets to be binary matrices (1s and 0s) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are passing a target array of shape (2000, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:\n```\nfrom keras.utils import to_categorical\ny_binary = to_categorical(y_int)\n```\n\nAlternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets."
     ]
    }
   ],
   "source": [
    "# Define a sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Define a hidden layer\n",
    "model.add(keras.layers.Dense(16, activation='relu', input_shape=(784,)))\n",
    "\n",
    "# Define the output layer\n",
    "model.add(keras.layers.Dense(4, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile('SGD', loss='categorical_crossentropy')\n",
    "\n",
    "# Complete the fitting operation\n",
    "model.fit(X, y, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
